# ğŸ  Brazilian Real Estate Market ETL Pipeline

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-14.0+-green.svg)](https://www.postgresql.org/)
[![Scrapy](https://img.shields.io/badge/Scrapy-2.5+-orange.svg)](https://scrapy.org/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

Um pipeline ETL completo para anÃ¡lise do mercado imobiliÃ¡rio brasileiro, com coleta automatizada de dados do OLX, processamento, armazenamento e visualizaÃ§Ã£o.

## ğŸ“‹ Ãndice
- [VisÃ£o Geral](#visÃ£o-geral)
- [Funcionalidades](#funcionalidades)
  - [ExtraÃ§Ã£o de Dados](#-extraÃ§Ã£o-de-dados)
  - [Processamento](#-processamento)
  - [Armazenamento](#-armazenamento)
  - [VisualizaÃ§Ã£o](#-visualizaÃ§Ã£o)
- [Tecnologias](#-tecnologias-utilizadas)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [Como Usar](#-como-usar)
- [Resultados e MÃ©tricas](#-resultados-e-mÃ©tricas)
  - [EstatÃ­sticas do Projeto](#estatÃ­sticas-do-projeto)
  - [Principais Insights](#-principais-insights)
- [Pipeline de Dados](#-pipeline-de-dados)
  - [Processo ETL](#processo-de-etl)
- [VisualizaÃ§Ãµes](#-visualizaÃ§Ãµes)
- [Banco de Dados](#-banco-de-dados)
- [AnÃ¡lises SQL e RelatÃ³rios](#-anÃ¡lises-sql-e-relatÃ³rios)
  - [AnÃ¡lises DisponÃ­veis](#-anÃ¡lises-disponÃ­veis)
  - [RelatÃ³rios Gerados](#-relatÃ³rios-gerados)
  - [MÃ©tricas Analisadas](#-principais-mÃ©tricas-analisadas)
- [LimitaÃ§Ãµes e ConsideraÃ§Ãµes](#-limitaÃ§Ãµes-e-consideraÃ§Ãµes)
- [LicenÃ§a](#-licenÃ§a
## ğŸ¯ VisÃ£o Geral

Este projeto implementa um pipeline de ETL (Extract, Transform, Load) para anÃ¡lise do mercado imobiliÃ¡rio brasileiro, utilizando dados do OLX. O sistema realiza:

- ExtraÃ§Ã£o automatizada de dados de imÃ³veis
- Limpeza e normalizaÃ§Ã£o dos dados
- Armazenamento em banco PostgreSQL
- GeraÃ§Ã£o de anÃ¡lises e visualizaÃ§Ãµes
- RelatÃ³rios de mercado 

## â­ Funcionalidades

### ğŸ” ExtraÃ§Ã£o de Dados
- Web scraping multi-thread
- Cobertura nacional (27 estados)
- Sistema anti-bloqueio
- GestÃ£o de sessÃµes e cookies

### ğŸ”„ Processamento
- Limpeza de dados
- NormalizaÃ§Ã£o de valores
- DetecÃ§Ã£o de outliers
- Enriquecimento de dados

### ğŸ’¾ Armazenamento
- Banco de dados PostgreSQL
- Modelo relacional otimizado

### ğŸ“Š VisualizaÃ§Ã£o
- AnÃ¡lises estatÃ­sticas
- GrÃ¡ficos interativos
- RelatÃ³rios em JSON
- Mapas de calor

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.8+**
- **PostgreSQL 14+**
- **Frameworks & Bibliotecas:**
  - Scrapy
  - CloudScraper
  - Pandas
  - NumPy
  - Matplotlib
  - Seaborn
  - psycopg2
  - Jupyter Notebooks
  - BeautifulSoup4

## ğŸ“ Estrutura do Projeto
```
etl_project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ final/                     # Dados finais processados
â”‚   â”œâ”€â”€ processed/                 # Dados intermediÃ¡rios processados
â”‚   â””â”€â”€ raw/                       # Dados brutos coletados
â”‚
â”œâ”€â”€ extract/
â”‚   â””â”€â”€ realstate/
â”‚       â”œâ”€â”€ pycache/            # Cache Python
â”‚       â”œâ”€â”€ pytest_cache/         # Cache de testes
â”‚       â”œâ”€â”€ clean_urls/           # URLs limpas
â”‚       â”œâ”€â”€ property_urls/        # URLs coletadas
â”‚       â”œâ”€â”€ realstate/           # MÃ³dulo principal
â”‚       â”œâ”€â”€ scrapy.cfg           # ConfiguraÃ§Ã£o Scrapy
â”‚       â”œâ”€â”€ test.py             # Testes
â”‚       â””â”€â”€ scraper.py          # Scraper principal
â”‚
â”œâ”€â”€ transform/
â”‚   â”œâ”€â”€ clean_data.ipynb         # Notebook de limpeza
â”‚   â”œâ”€â”€ clean_location.ipynb     # Processamento de localizaÃ§Ã£o
â”‚   â”œâ”€â”€ clean_urls.py           # Limpeza de URLs
â”‚   â””â”€â”€ outliers.ipynb          # Tratamento de outliers
â”‚
â”œâ”€â”€ load/
â”‚   â””â”€â”€ load.py                 # Script de carga no banco
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ market_report.json
â”‚   â””â”€â”€ scraping_report_20241106_171212.json
â”‚
â”œâ”€â”€ SQL_viz/
â”‚   â”œâ”€â”€ results                # Resultados das anÃ¡lises
â”‚   â”‚   â”œâ”€â”€ analysis_report_20241111.json
â”‚   â”‚   â”œâ”€â”€ investment_score_20241111.csv
â”‚   â”‚   â”œâ”€â”€ investment_score_20241111.json
â”‚   â”‚   â”œâ”€â”€ premium_analysis_20241111.csv
â”‚   â”‚   â”œâ”€â”€ premium_analysis_20241111.json
â”‚   â”‚   â”œâ”€â”€ regional_analysis_20241111.csv
â”‚   â”‚   â”œâ”€â”€ regional_analysis_20241111.json
â”‚   â”‚   â”œâ”€â”€ top_neighborhoods_20241111.csv
â”‚   â”‚   â””â”€â”€ top_neighborhoods_20241111.json
â”‚   â”œâ”€â”€ sql/                    # Queries SQL
â”‚   â”‚   â”œâ”€â”€ investment_score.sql
â”‚   â”‚   â”œâ”€â”€ premium_analysis.sql
â”‚   â”‚   â”œâ”€â”€ regional_analysis.sql
â”‚   â”‚   â””â”€â”€ top_neighborhoods.sql
â”‚   â””â”€â”€ main.py                # Script principal de anÃ¡lise
â”‚
â”œâ”€â”€ visualizations/
â”‚   â”œâ”€â”€ amenities_analysis.png
â”‚   â”œâ”€â”€ area_vs_price_scatter.png
â”‚   â”œâ”€â”€ price_distribution_by_state.png
â”‚   â”œâ”€â”€ price_distribution.png
â”‚   â”œâ”€â”€ price_per_m2_heatmap.png
â”‚   â”œâ”€â”€ property_type_distribution.png
â”‚   â””â”€â”€ viz.py
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ accuracy.py
â”œâ”€â”€ database_import.log
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
â””â”€â”€ LICENSE
```

## ğŸš€ InstalaÃ§Ã£o

1. **Clone o repositÃ³rio**
```bash
git clone https://github.com/seu-usuario/olx-real-estate-etl.git
cd olx-real-estate-etl
```

2. **Crie um ambiente virtual**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

3. **Instale as dependÃªncias**
```bash
pip install -r requirements.txt
```

4. **Configure o PostgreSQL**
```bash
# Crie o banco de dados
createdb real_estate_db

# Configure as variÃ¡veis de ambiente
export DB_HOST=localhost
export DB_NAME=real_estate_db
export DB_USER=seu_usuario
export DB_PASSWORD=sua_senha
```

## ğŸ’» Como Usar

### 1. ExtraÃ§Ã£o de Dados
```bash
# Execute a spider
cd extract/realstate
scrapy crawl realstatespider

# Execute o scraper
python scraper.py
```

### 2. TransformaÃ§Ã£o
```bash
# Execute os scripts de transformaÃ§Ã£o
python transform/clean_data.py
python transform/clean_location.py
python transform/outliers.py
```

### 3. Carga
```bash
# Carregue os dados no PostgreSQL
python load/database.py
```

### 4. VisualizaÃ§Ã£o
```bash
# Gere as visualizaÃ§Ãµes
python visualizations/viz.py
```

## ğŸ“Š VisualizaÃ§Ãµes

O projeto gera diversas visualizaÃ§Ãµes:

- **DistribuiÃ§Ã£o de PreÃ§os**
  - Por estado
  - Por tipo de imÃ³vel
  - Por mÂ²

- **AnÃ¡lises GeogrÃ¡ficas**
  - Heatmaps de preÃ§os
  - ConcentraÃ§Ã£o de ofertas
  - Comparativos regionais

- **AnÃ¡lise de CaracterÃ­sticas**
  - RelaÃ§Ã£o Ã¡rea/preÃ§o
  - Impacto de amenidades
  - DistribuiÃ§Ã£o de tipos

## ğŸ—„ï¸ Banco de Dados

### Modelo de Dados
```sql
-- Estrutura principal das tabelas
CREATE TABLE locations (
    location_id SERIAL PRIMARY KEY,
    neighborhood VARCHAR(100),
    city VARCHAR(100),
    state VARCHAR(2),
    cep VARCHAR(8)
);

CREATE TABLE properties (
    property_id SERIAL PRIMARY KEY,
    price NUMERIC(12,2),
    area_util NUMERIC(8,2),
    bedrooms SMALLINT,
    location_id INTEGER REFERENCES locations(location_id)
);
```

## ğŸ“ˆ AnÃ¡lises Geradas

### RelatÃ³rio de Mercado
```json
{
    "market_summary": {
        "total_properties": "nÃºmero total",
        "average_price": "preÃ§o mÃ©dio",
        "price_range": {
            "min": "valor mÃ­nimo",
            "max": "valor mÃ¡ximo"
        }
    }
}
```
## ğŸ“Š AnÃ¡lises SQL e RelatÃ³rios

### ğŸ“‚ LocalizaÃ§Ã£o dos Arquivos
As anÃ¡lises SQL e seus resultados podem ser encontrados no diretÃ³rio `SQL_viz/`:

SQL_viz/
â”œâ”€â”€ results/                # Resultados das anÃ¡lises
â”‚   â”œâ”€â”€ analysis_report_20241111.json
â”‚   â”œâ”€â”€ investment_score_20241111.csv
â”‚   â”œâ”€â”€ premium_analysis_20241111.csv
â”‚   â”œâ”€â”€ regional_analysis_20241111.csv
â”‚   â””â”€â”€ top_neighborhoods_20241111.csv
â””â”€â”€ sql/                   # Queries SQL
â”œâ”€â”€ investment_score.sql
â”œâ”€â”€ premium_analysis.sql
â”œâ”€â”€ regional_analysis.sql
â””â”€â”€ top_neighborhoods.sql

### ğŸ” AnÃ¡lises DisponÃ­veis

#### 1. Score de Investimento (`investment_score.sql`)
- AnÃ¡lise complexa que gera um score de investimento por cidade
- Considera fatores como preÃ§o/mÂ², densidade do mercado e amenidades
- **Exemplo de Resultado:**

BalneÃ¡rio CamboriÃº (SC): 72.25
Nova Lima (MG): 64.21
Manaus (AM): 63.41

#### 2. AnÃ¡lise Premium (`premium_analysis.sql`)
- IdentificaÃ§Ã£o e anÃ¡lise de imÃ³veis no segmento premium
- AvaliaÃ§Ã£o de caracterÃ­sticas e distribuiÃ§Ã£o geogrÃ¡fica
- MÃ©tricas de valorizaÃ§Ã£o por regiÃ£o

#### 3. AnÃ¡lise Regional (`regional_analysis.sql`)
- Comparativo entre diferentes regiÃµes do paÃ­s
- Indicadores de mercado por estado
- TendÃªncias de preÃ§os por localidade

#### 4. AnÃ¡lise de Bairros (`top_neighborhoods.sql`)
- Ranking dos bairros mais valorizados
- Densidade de ofertas por regiÃ£o
- MÃ©tricas de preÃ§o por mÂ² por bairro

### ğŸ“ˆ RelatÃ³rios Gerados

Os relatÃ³rios podem ser encontrados em dois formatos:

1. **CSV** (`SQL_viz/results/*.csv`)
 - Dados tabulares para anÃ¡lise
 - FÃ¡cil importaÃ§Ã£o em ferramentas de anÃ¡lise
 - Formato ideal para processamento posterior

2. **JSON** (`SQL_viz/results/*.json`)
 - Dados estruturados com metadados
 - Ideal para integraÃ§Ã£o com outras aplicaÃ§Ãµes
 - Inclui mÃ©tricas e estatÃ­sticas agregadas

### ğŸ“Š Principais MÃ©tricas Analisadas

1. **MÃ©tricas de PreÃ§o**
 - PreÃ§o mÃ©dio por mÂ²
 - VariaÃ§Ã£o de preÃ§os
 - TendÃªncias por segmento

2. **MÃ©tricas de Mercado**
 - Densidade de ofertas
 - DistribuiÃ§Ã£o por tipo
 - ConcentraÃ§Ã£o geogrÃ¡fica

3. **MÃ©tricas de Investimento**
 - Score de investimento
 - Potencial de valorizaÃ§Ã£o
 - Indicadores de qualidade

### ğŸ’» ExecuÃ§Ã£o das AnÃ¡lises

Para executar as anÃ¡lises SQL e gerar os relatÃ³rios:

```bash
cd SQL_viz
python main.py

Os resultados serÃ£o salvos em:

CSVs em SQL_viz/results/*.csv
JSONs em SQL_viz/results/*.json
RelatÃ³rio consolidado em SQL_viz/results/analysis_report_[DATA].json

Para mais detalhes sobre as queries e anÃ¡lises especÃ­ficas, consulte os arquivos SQL em SQL_viz/sql/.

## ğŸ“Š Resultados e MÃ©tricas

### EstatÃ­sticas do Projeto
- **Cobertura**: 27 estados brasileiros
- **Volume de Dados**: +60.000 imÃ³veis analisados
- **Taxa de Sucesso**: 96.52% na coleta de dados
- **PrecisÃ£o**: Alta confiabilidade apÃ³s limpeza e normalizaÃ§Ã£o

### ğŸ† Principais Insights
1. **Mercados Premium**
   - Ipojuca (PE) lidera com maior preÃ§o/mÂ², mais de R$ 15.000,00
   - Nova Lima (MG) destacada no segmento luxo
   - Manaus (AM) apresenta mercado aquecido
   - 

2. **TendÃªncias Identificadas**
   - ConcentraÃ§Ã£o de alto valor em capitais
   - CorrelaÃ§Ã£o forte entre amenidades e preÃ§o
   - PadrÃµes regionais de valorizaÃ§Ã£o

## ğŸ”„ Pipeline de Dados

### Processo de ETL
1. **Extract**
   - Coleta distribuÃ­da por estado
   - Sistema anti-bloqueio 
   - ValidaÃ§Ã£o de dados na origem

2. **Transform**
   - Limpeza e padronizaÃ§Ã£o
   - DetecÃ§Ã£o de anomalias
   - Enriquecimento geogrÃ¡fico, separando uma coluna em 4

3. **Load**
   - Modelagem otimizada
   - Ãndices eficientes
   - Backup automÃ¡tico

## âš ï¸ LimitaÃ§Ãµes e ConsideraÃ§Ãµes

- Dados limitados ao perÃ­odo de coleta
- Foco em imÃ³veis Ã  venda (nÃ£o inclui aluguel)
- DependÃªncia da disponibilidade da fonte
- PossÃ­veis variaÃ§Ãµes sazonais
- Alguns imÃ³veis com dados corrompidos ou mal estruturados
- Demora na extraÃ§Ã£o de dados, por motivos de poder computacional


## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.
